#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script l∆∞u k·∫øt qu·∫£ crawl v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin
"""

import json
import time
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from fake_useragent import UserAgent
import unicodedata

def crawl_and_save_results():
    """Crawl data v√† l∆∞u k·∫øt qu·∫£"""
    print("üíæ === CRAWL V√Ä L∆ØU K·∫æT QU·∫¢ ===")
    
    # URL test
    url = "https://webcamera24.com/camera/austria/radstadt-cow-sanctuary-cam/?_rsc=1xov6"
    print(f"URL: {url}")
    
    driver = None
    
    try:
        # Thi·∫øt l·∫≠p Chrome options
        print("\nüîÑ Thi·∫øt l·∫≠p Chrome options...")
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-plugins')
        # Force English locale for requests and rendering
        chrome_options.add_argument('--lang=en-US')
        chrome_prefs = {
            'intl.accept_languages': 'en-US,en'
        }
        chrome_options.add_experimental_option('prefs', chrome_prefs)
        
        # User agent
        ua = UserAgent()
        chrome_options.add_argument(f'--user-agent={ua.random}')
        
        # Kh·ªüi t·∫°o WebDriver
        print("üöó Kh·ªüi t·∫°o WebDriver...")
        try:
            driver = webdriver.Chrome(options=chrome_options)
            print("‚úÖ ChromeDriver ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng")
        except Exception as e:
            print(f"‚ùå ChromeDriver failed: {e}")
            return False
        
        # Truy c·∫≠p trang (√©p English n·∫øu URL c√≥ /vi/)
        if '/vi/' in url:
            url_to_visit = url.replace('/vi/', '/en/')
        else:
            url_to_visit = url
        print(f"\nüåê ƒêang truy c·∫≠p: {url_to_visit}")
        driver.get(url_to_visit)
        
        # Ch·ªù page load
        print("‚è≥ Ch·ªù page load...")
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # Ch·ªù th√™m m·ªôt ch√∫t ƒë·ªÉ JavaScript render (kh√¥ng scroll/zoom map)
        time.sleep(2)

        # L·∫•y page source sau khi zoom
        print("üìÑ L·∫•y page source...")
        page_source = driver.page_source
        
        # Parse HTML
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # Tr√≠ch xu·∫•t th√¥ng tin
        print("üîç Tr√≠ch xu·∫•t th√¥ng tin...")
        
        # T·∫°o k·∫øt qu·∫£
        result = {
            'url': url,
            'timestamp': datetime.now().isoformat(),
            'method': 'selenium',
            'status': 'success',
            'page_info': {
                'title': '',
                'h1': '',
                'meta_description': '',
                'content_length': len(page_source)
            },
            'location': {
                'breadcrumbs': [],
                'location_from_url': '',
                'location_from_page': '',
                'coordinates': {
                    'latitude': None,
                    'longitude': None,
                    'zoom': None,
                    'source': ''
                }
            },
            'camera_info': {
                'youtube_streams': {},
                'thumbnails': [],
                'other_streams': [],
                'embed_codes': []
            },
            'map_info': {
                'openstreetmap': {},
                'google_maps': {},
                'other_maps': []
            }
        }
        
        # Tr√≠ch xu·∫•t title: ∆∞u ti√™n h1.page-heading theo y√™u c·∫ßu
        h1_heading = soup.find('h1', class_='page-heading')
        if h1_heading and h1_heading.get_text(strip=True):
            result['page_info']['title'] = h1_heading.get_text(strip=True)
            result['page_info']['h1'] = result['page_info']['title']
        else:
            # Fallback <title>
            title_tag = soup.find('title')
            if title_tag:
                result['page_info']['title'] = title_tag.get_text(strip=True)
            # Fallback H1 b·∫•t k·ª≥
            h1_tags = soup.find_all('h1')
            if h1_tags and not result['page_info']['h1']:
                result['page_info']['h1'] = h1_tags[0].get_text(strip=True)
        
        # Tr√≠ch xu·∫•t meta description
        meta_desc = soup.find('meta', attrs={'name': 'description'})
        if meta_desc:
            result['page_info']['meta_description'] = meta_desc.get('content', '')
        
        # Tr√≠ch xu·∫•t breadcrumbs
        breadcrumbs = soup.find_all(['nav', 'ol', 'ul'], class_=lambda x: x and 'breadcrumb' in x.lower())
        for breadcrumb in breadcrumbs:
            breadcrumb_data = []
            links = breadcrumb.find_all('a')
            for link in links:
                text = link.get_text(strip=True)
                href = link.get('href', '')
                breadcrumb_data.append({
                    'text': text,
                    'url': href,
                    'title': link.get('title', '')
                })
            if breadcrumb_data:
                result['location']['breadcrumbs'].append(breadcrumb_data)
        
        # Tr√≠ch xu·∫•t location t·ª´ URL
        from urllib.parse import urlparse
        parsed = urlparse(url)
        path_parts = parsed.path.strip('/').split('/')
        if 'vietnam' in path_parts:
            result['location']['location_from_url'] = "Vietnam"
        if 'quang-trung' in path_parts:
            result['location']['location_from_url'] = "Quang Trung Street, Vietnam"
        
        # Tr√≠ch xu·∫•t JSON-LD data
        json_ld_scripts = soup.find_all('script', type='application/ld+json')
        for script in json_ld_scripts:
            text = (script.string or script.get_text() or '').strip()
            if not text:
                continue
            try:
                data = json.loads(text)
            except Exception as e:
                print(f"L·ªói parse JSON-LD: {e}")
                continue

            def _harvest_from_obj(obj):
                if not isinstance(obj, dict):
                    return
                # YouTube streams
                embed = obj.get('embedUrl')
                content = obj.get('contentUrl')
                thumb = obj.get('thumbnailUrl')
                if embed and 'embedUrl' not in result['camera_info']['youtube_streams']:
                    result['camera_info']['youtube_streams']['embedUrl'] = embed
                if content and 'contentUrl' not in result['camera_info']['youtube_streams']:
                    result['camera_info']['youtube_streams']['contentUrl'] = content
                if thumb and 'thumbnailUrl' not in result['camera_info']['youtube_streams']:
                    # thumbnailUrl c√≥ th·ªÉ l√† list ho·∫∑c str
                    if isinstance(thumb, list):
                        if thumb:
                            result['camera_info']['youtube_streams']['thumbnailUrl'] = thumb[0]
                    elif isinstance(thumb, str):
                        result['camera_info']['youtube_streams']['thumbnailUrl'] = thumb

                # Thumbnails list
                if thumb:
                    thumb_url = thumb[0] if isinstance(thumb, list) and thumb else thumb
                    if thumb_url:
                        result['camera_info']['thumbnails'].append({
                            'type': 'json_ld',
                            'url': thumb_url,
                            'source': 'thumbnailUrl'
                        })

                # Location t·ª´ JSON-LD
                if 'name' in obj and not result['location']['location_from_page']:
                    result['location']['location_from_page'] = obj['name']

                # N·∫øu c√≥ @graph, duy·ªát ti·∫øp
                if '@graph' in obj and isinstance(obj['@graph'], list):
                    for it in obj['@graph']:
                        _harvest_from_obj(it)

            if isinstance(data, dict):
                _harvest_from_obj(data)
            elif isinstance(data, list):
                for item in data:
                    _harvest_from_obj(item)
        
        # Tr√≠ch xu·∫•t iframe YouTube
        iframes = soup.find_all('iframe')
        for iframe in iframes:
            src = iframe.get('src', '')
            if 'youtube.com' in src or 'youtu.be' in src or 'youtube-nocookie.com' in src:
                if 'embedUrl' not in result['camera_info']['youtube_streams']:
                    result['camera_info']['youtube_streams']['embedUrl'] = src
                
                # Chuy·ªÉn ƒë·ªïi embed URL th√†nh content URL
                if '/embed/' in src:
                    video_id = src.split('/embed/')[-1].split('?')[0]
                    if 'contentUrl' not in result['camera_info']['youtube_streams']:
                        result['camera_info']['youtube_streams']['contentUrl'] = f'https://www.youtube.com/watch?v={video_id}'

        # Fallback thumbnail t·ª´ meta tags n·∫øu thi·∫øu
        if not result['camera_info']['youtube_streams'].get('thumbnailUrl'):
            og_image = soup.find('meta', attrs={'property': 'og:image'})
            if og_image and og_image.get('content'):
                result['camera_info']['youtube_streams']['thumbnailUrl'] = og_image.get('content')
                result['camera_info']['thumbnails'].append({
                    'type': 'meta',
                    'url': og_image.get('content'),
                    'source': 'og:image'
                })
            else:
                tw_image = soup.find('meta', attrs={'name': 'twitter:image'})
                if tw_image and tw_image.get('content'):
                    result['camera_info']['youtube_streams']['thumbnailUrl'] = tw_image.get('content')
                    result['camera_info']['thumbnails'].append({
                        'type': 'meta',
                        'url': tw_image.get('content'),
                        'source': 'twitter:image'
                    })
        
        # Tr√≠ch xu·∫•t th√¥ng tin b·∫£n ƒë·ªì v√† t·ªça ƒë·ªô
        print("üó∫Ô∏è  Tr√≠ch xu·∫•t th√¥ng tin b·∫£n ƒë·ªì...")
        map_info = extract_map_information(soup, driver)
        result['map_info'].update(map_info)
        
        # Tr√≠ch xu·∫•t t·ªça ƒë·ªô t·ª´ OpenStreetMap
        print("üó∫Ô∏è  Tr√≠ch xu·∫•t t·ªça ƒë·ªô OpenStreetMap...")
        coordinates = extract_openstreetmap_coordinates(soup, driver)
        if coordinates:
            result['location']['coordinates'].update(coordinates)
        
        # Tr√≠ch xu·∫•t t·ªça ƒë·ªô t·ª´ b·∫£n ƒë·ªì (fallback)
        if not coordinates.get('latitude'):
            coordinates = extract_coordinates(soup, driver)
            if coordinates:
                result['location']['coordinates'].update(coordinates)
        
        # Country theo breadcrumb title anchor (generic: /countries/<country>/)
        country = ''
        try:
            from urllib.parse import urlparse
            for trail in result['location'].get('breadcrumbs', []) or []:
                for crumb in trail:
                    href = str(crumb.get('url', ''))
                    title_attr = str(crumb.get('title', '')).strip()
                    parts = urlparse(href).path.strip('/').split('/')
                    # /countries/<country>/ -> len(parts)==2
                    if len(parts) == 2 and parts[0] == 'countries':
                        country = title_attr or parts[1].replace('-', ' ').title()
                        raise StopIteration
        except StopIteration:
            pass
        if not country:
            from urllib.parse import urlparse
            parts = urlparse(url).path.strip('/').split('/')
            if len(parts) >= 2 and parts[0] == 'countries':
                country = parts[1].replace('-', ' ').title()

        yt = result['camera_info'].get('youtube_streams', {})
        
        # City t·ª´ breadcrumb title anchor (generic: /countries/<country>/<city>/)
        city = ''
        try:
            from urllib.parse import urlparse
            for trail in result['location'].get('breadcrumbs', []) or []:
                for crumb in trail:
                    href = str(crumb.get('url', ''))
                    title_attr = str(crumb.get('title', '')).strip()
                    parts = urlparse(href).path.strip('/').split('/')
                    # /countries/<country>/<city>/ -> len(parts)==3
                    if len(parts) == 3 and parts[0] == 'countries':
                        city = title_attr or parts[2].replace('-', ' ').title()
                        raise StopIteration
        except StopIteration:
            pass
        if not city:
            # fallback from URL path
            from urllib.parse import urlparse
            parts = urlparse(url).path.strip('/').split('/')
            if len(parts) >= 3 and parts[0] == 'countries':
                city = parts[2].replace('-', ' ').title()
        if not city:
            city = infer_city_english(result, url)
        # Final fallback: if still empty, use country as city
        if not city:
            city = country
        
        # D√πng tr·ª±c ti·∫øp title ƒë√£ l·∫•y t·ª´ h1.page-heading (ƒë√£ l√† English khi truy c·∫≠p /en/)
        eng_title = result['page_info'].get('title', '')
        minimal_result = {
            'embedUrl': yt.get('embedUrl', ''),
            'contentUrl': yt.get('contentUrl', ''),
            'thumbnailUrl': yt.get('thumbnailUrl', ''),
            'country': country,
            'city': city,
            'title': eng_title
        }

        # B·ªè qua n·∫øu kh√¥ng c√≥ URL (embed/content)
        if not (minimal_result.get('embedUrl') or minimal_result.get('contentUrl')):
            print("‚ö†Ô∏è B·ªè qua: kh√¥ng c√≥ embedUrl/contentUrl")
            return True

        # L∆∞u k·∫øt qu·∫£ (t·ªëi gi·∫£n theo y√™u c·∫ßu) v·ªõi t√™n file = country
        safe_country = (country or 'Unknown').strip().replace(' ', '_')
        filename = f"{safe_country}.json"
        print(f"\nüíæ ƒêang l∆∞u k·∫øt qu·∫£ v√†o: {filename}")
        # Tr√°nh ghi ƒë√®: n·∫øu file country ƒë√£ t·ªìn t·∫°i, merge th√†nh m·∫£ng
        try:
            import os
            if os.path.exists(filename):
                with open(filename, 'r', encoding='utf-8') as rf:
                    try:
                        existing = json.load(rf)
                    except Exception:
                        existing = None
                merged = None
                if isinstance(existing, list):
                    # L·ªçc b·ªè c√°c entry c≈© kh√¥ng c√≥ URL
                    existing = [it for it in existing if isinstance(it, dict) and (it.get('embedUrl') or it.get('contentUrl'))]
                    merged = existing
                    # dedupe theo embedUrl ho·∫∑c title
                    keys = {(item.get('embedUrl'), item.get('title')) for item in existing if isinstance(item, dict)}
                    if (minimal_result.get('embedUrl'), minimal_result.get('title')) not in keys and (minimal_result.get('embedUrl') or minimal_result.get('contentUrl')):
                        merged.append(minimal_result)
                elif isinstance(existing, dict) and existing:
                    # chuy·ªÉn sang list
                    # B·ªè dict n·∫øu kh√¥ng c√≥ URL
                    merged = [existing] if (existing.get('embedUrl') or existing.get('contentUrl')) else []
                    if (minimal_result.get('embedUrl') or minimal_result.get('contentUrl')) and not (existing.get('embedUrl') == minimal_result.get('embedUrl') and existing.get('title') == minimal_result.get('title')):
                        merged.append(minimal_result)
                else:
                    merged = [minimal_result]
                with open(filename, 'w', encoding='utf-8') as wf:
                    json.dump(merged, wf, ensure_ascii=False, indent=2)
            else:
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(minimal_result, f, ensure_ascii=False, indent=2)
        except Exception:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(minimal_result, f, ensure_ascii=False, indent=2)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ t√≥m t·∫Øt (t·ªëi gi·∫£n)
        print("\nüìä K·∫øt qu·∫£ crawl (t·ªëi gi·∫£n):")
        print(f"üìù Title: {minimal_result['title']}")
        print(f"üåç Country: {minimal_result['country']}")
        print(f"üèôÔ∏è  City: {minimal_result['city']}")
        print(f"üé• embedUrl: {minimal_result['embedUrl']}")
        print(f"üé• contentUrl: {minimal_result['contentUrl']}")
        print(f"üñºÔ∏è  thumbnailUrl: {minimal_result['thumbnailUrl']}")
        
        print(f"\nüíæ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {filename}")
        print("üéâ Crawl v√† l∆∞u k·∫øt qu·∫£ ho√†n th√†nh!")
        
        return True
        
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # D·ªçn d·∫πp
        if driver:
            driver.quit()
            print("üöó WebDriver ƒë√£ ƒë∆∞·ª£c ƒë√≥ng")

def extract_map_information(soup, driver):
    """Tr√≠ch xu·∫•t th√¥ng tin b·∫£n ƒë·ªì"""
    map_info = {
        'openstreetmap': {},
        'google_maps': {},
        'other_maps': []
    }
    
    try:
        # T√¨m ki·∫øm OpenStreetMap
        osm_elements = soup.find_all(['div', 'iframe'], class_=lambda x: x and any(keyword in x.lower() for keyword in ['map', 'osm', 'openstreetmap', 'leaflet']))
        
        for element in osm_elements:
            # Ki·ªÉm tra iframe OpenStreetMap
            if element.name == 'iframe':
                src = element.get('src', '')
                if any(domain in src.lower() for domain in ['openstreetmap.org', 'osm.org', 'leaflet']):
                    map_info['openstreetmap']['iframe_src'] = src
                    map_info['openstreetmap']['type'] = 'iframe'
            
            # Ki·ªÉm tra div ch·ª©a b·∫£n ƒë·ªì
            elif element.name == 'div':
                # T√¨m ki·∫øm data attributes ch·ª©a t·ªça ƒë·ªô
                for attr, value in element.attrs.items():
                    if any(keyword in attr.lower() for keyword in ['lat', 'lon', 'zoom', 'center']):
                        map_info['openstreetmap'][attr] = value
                
                # T√¨m ki·∫øm trong data attributes
                data_lat = element.get('data-lat') or element.get('data-latitude')
                data_lon = element.get('data-lon') or element.get('data-longitude')
                data_zoom = element.get('data-zoom')
                
                if data_lat and data_lon:
                    map_info['openstreetmap']['data_lat'] = data_lat
                    map_info['openstreetmap']['data_lon'] = data_lon
                    if data_zoom:
                        map_info['openstreetmap']['data_zoom'] = data_zoom
        
        # T√¨m ki·∫øm Google Maps
        google_elements = soup.find_all(['div', 'iframe'], class_=lambda x: x and any(keyword in x.lower() for keyword in ['google-map', 'googlemap', 'gmap']))
        
        for element in google_elements:
            if element.name == 'iframe':
                src = element.get('src', '')
                if 'google.com/maps' in src or 'maps.google.com' in src:
                    map_info['google_maps']['iframe_src'] = src
                    map_info['google_maps']['type'] = 'iframe'
            
            # T√¨m ki·∫øm data attributes c·ªßa Google Maps
            for attr, value in element.attrs.items():
                if any(keyword in attr.lower() for keyword in ['lat', 'lng', 'zoom', 'center']):
                    map_info['google_maps'][attr] = value
        
        # T√¨m ki·∫øm trong scripts
        scripts = soup.find_all('script')
        for script in scripts:
            if script.string:
                script_content = script.string
                
                # T√¨m ki·∫øm OpenStreetMap coordinates
                import re
                osm_patterns = [
                    r'lat["\']?\s*:\s*([0-9.-]+)',
                    r'lon["\']?\s*:\s*([0-9.-]+)',
                    r'latitude["\']?\s*:\s*([0-9.-]+)',
                    r'longitude["\']?\s*:\s*([0-9.-]+)',
                    r'center["\']?\s*:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                    r'zoom["\']?\s*:\s*([0-9]+)',
                    # Th√™m c√°c pattern cho Leaflet/OpenStreetMap
                    r'L\.map\(["\']([^"\']+)["\']\s*,\s*{\s*center:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                    r'setView\(\[([0-9.-]+),\s*([0-9.-]+)\]\s*,\s*([0-9]+)',
                    r'center:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                    r'lat:\s*([0-9.-]+)',
                    r'lng:\s*([0-9.-]+)',
                    r'zoom:\s*([0-9]+)',
                    # Th√™m c√°c pattern cho React/Next.js
                    r'position["\']?\s*:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                    r'coordinates["\']?\s*:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                    r'location["\']?\s*:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                    # Pattern cho JSON data
                    r'"lat":\s*([0-9.-]+)',
                    r'"lon":\s*([0-9.-]+)',
                    r'"latitude":\s*([0-9.-]+)',
                    r'"longitude":\s*([0-9.-]+)',
                    r'"center":\s*\[([0-9.-]+),\s*([0-9.-]+)\]'
                ]
                
                for pattern in osm_patterns:
                    matches = re.findall(pattern, script_content)
                    for match in matches:
                        if 'center' in pattern:
                            if len(match) == 2:
                                map_info['openstreetmap']['center_lat'] = match[0]
                                map_info['openstreetmap']['center_lon'] = match[1]
                        elif 'lat' in pattern or 'latitude' in pattern:
                            map_info['openstreetmap']['lat'] = match
                        elif 'lon' in pattern or 'longitude' in pattern:
                            map_info['openstreetmap']['lon'] = match
                        elif 'zoom' in pattern:
                            map_info['openstreetmap']['zoom'] = match
                
                # T√¨m ki·∫øm Google Maps coordinates
                google_patterns = [
                    r'google\.maps\.LatLng\(([0-9.-]+),\s*([0-9.-]+)\)',
                    r'center["\']?\s*:\s*new\s+google\.maps\.LatLng\(([0-9.-]+),\s*([0-9.-]+)\)',
                    r'zoom["\']?\s*:\s*([0-9]+)'
                ]
                
                for pattern in google_patterns:
                    matches = re.findall(pattern, script_content)
                    for match in matches:
                        if 'LatLng' in pattern:
                            if len(match) == 2:
                                map_info['google_maps']['lat'] = match[0]
                                map_info['google_maps']['lng'] = match[1]
                        elif 'zoom' in pattern:
                            map_info['google_maps']['zoom'] = match
        
        # T√¨m ki·∫øm c√°c lo·∫°i b·∫£n ƒë·ªì kh√°c
        other_map_elements = soup.find_all(['div', 'iframe'], class_=lambda x: x and any(keyword in x.lower() for keyword in ['map', 'b·∫£n ƒë·ªì', 'carto', 'mapbox']))
        
        for element in other_map_elements:
            if element.name == 'iframe':
                src = element.get('src', '')
                if src and 'map' in src.lower():
                    map_info['other_maps'].append({
                        'type': 'iframe',
                        'src': src,
                        'class': element.get('class', [])
                    })
            else:
                map_info['other_maps'].append({
                    'type': 'div',
                    'class': element.get('class', []),
                    'id': element.get('id', ''),
                    'attrs': dict(element.attrs)
                })
    
    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t th√¥ng tin b·∫£n ƒë·ªì: {e}")
    
    return map_info

def extract_coordinates(soup, driver):
    """Tr√≠ch xu·∫•t t·ªça ƒë·ªô t·ª´ b·∫£n ƒë·ªì"""
    coordinates = {}
    
    try:
        # T√¨m ki·∫øm t·ªça ƒë·ªô t·ª´ OpenStreetMap
        osm_info = {}
        
        # T√¨m ki·∫øm trong data attributes
        map_divs = soup.find_all('div', class_=lambda x: x and 'map' in x.lower())
        for div in map_divs:
            data_lat = div.get('data-lat') or div.get('data-latitude')
            data_lon = div.get('data-lon') or div.get('data-longitude')
            data_zoom = div.get('data-zoom')
            
            if data_lat and data_lon:
                osm_info['data_lat'] = data_lat
                osm_info['data_lon'] = data_lon
                if data_zoom:
                    osm_info['data_zoom'] = data_zoom
        
        # T√¨m ki·∫øm trong c√°c div c√≥ class ch·ª©a 'Map'
        map_class_divs = soup.find_all('div', class_=lambda x: x and any(keyword in x for keyword in ['Map', 'map']))
        for div in map_class_divs:
            # Ki·ªÉm tra t·∫•t c·∫£ attributes
            for attr, value in div.attrs.items():
                if any(keyword in attr.lower() for keyword in ['lat', 'lon', 'zoom', 'center', 'coord']):
                    osm_info[f'map_{attr}'] = value
                
                # Ki·ªÉm tra data attributes
                if attr.startswith('data-'):
                    if any(keyword in attr.lower() for keyword in ['lat', 'lon', 'zoom', 'center', 'coord']):
                        osm_info[f'data_{attr}'] = value
        
        # T√¨m ki·∫øm trong scripts
        scripts = soup.find_all('script')
        for script in scripts:
            if script.string:
                script_content = script.string
                
                import re
                # T√¨m ki·∫øm t·ªça ƒë·ªô OpenStreetMap
                osm_patterns = [
                    r'lat["\']?\s*:\s*([0-9.-]+)',
                    r'lon["\']?\s*:\s*([0-9.-]+)',
                    r'latitude["\']?\s*:\s*([0-9.-]+)',
                    r'longitude["\']?\s*:\s*([0-9.-]+)',
                    r'center["\']?\s*:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                    r'zoom["\']?\s*:\s*([0-9]+)'
                ]
                
                for i, pattern in enumerate(osm_patterns):
                    matches = re.findall(pattern, script_content)
                    for match in matches:
                        if 'center' in pattern and 'L\.map' not in pattern:
                            if len(match) == 2:
                                osm_info['center_lat'] = match[0]
                                osm_info['center_lon'] = match[1]
                        elif 'L\.map' in pattern:
                            if len(match) == 3:
                                osm_info['map_id'] = match[0]
                                osm_info['center_lat'] = match[0]
                                osm_info['center_lon'] = match[1]
                        elif 'setView' in pattern:
                            if len(match) == 3:
                                osm_info['center_lat'] = match[0]
                                osm_info['center_lon'] = match[1]
                                osm_info['zoom'] = match[2]
                        elif 'position' in pattern or 'coordinates' in pattern or 'location' in pattern:
                            if len(match) == 2:
                                osm_info['center_lat'] = match[0]
                                osm_info['center_lon'] = match[1]
                        elif 'lat' in pattern or 'latitude' in pattern:
                            osm_info['lat'] = match
                        elif 'lon' in pattern or 'longitude' in pattern:
                            osm_info['lon'] = match
                        elif 'lng' in pattern:
                            osm_info['lon'] = match
                        elif 'zoom' in pattern:
                            osm_info['zoom'] = match
                
                # T√¨m ki·∫øm t·ªça ƒë·ªô Google Maps
                google_patterns = [
                    r'google\.maps\.LatLng\(([0-9.-]+),\s*([0-9.-]+)\)',
                    r'center["\']?\s*:\s*new\s+google\.maps\.LatLng\(([0-9.-]+),\s*([0-9.-]+)\)',
                    r'zoom["\']?\s*:\s*([0-9]+)'
                ]
                
                for pattern in google_patterns:
                    matches = re.findall(pattern, script_content)
                    for match in matches:
                        if 'LatLng' in pattern:
                            if len(match) == 2:
                                osm_info['google_lat'] = match[0]
                                osm_info['google_lon'] = match[1]
                        elif 'zoom' in pattern:
                            osm_info['google_zoom'] = match
        
        # ∆Øu ti√™n t·ªça ƒë·ªô t·ª´ OpenStreetMap
        if 'lat' in osm_info and 'lon' in osm_info:
            coordinates['latitude'] = osm_info['lat']
            coordinates['longitude'] = osm_info['lon']
            coordinates['source'] = 'openstreetmap_data'
            if 'zoom' in osm_info:
                coordinates['zoom'] = osm_info['zoom']
        elif 'center_lat' in osm_info and 'center_lon' in osm_info:
            coordinates['latitude'] = osm_info['center_lat']
            coordinates['longitude'] = osm_info['center_lon']
            coordinates['source'] = 'openstreetmap_center'
            if 'zoom' in osm_info:
                coordinates['zoom'] = osm_info['zoom']
        elif 'google_lat' in osm_info and 'google_lon' in osm_info:
            coordinates['latitude'] = osm_info['google_lat']
            coordinates['longitude'] = osm_info['google_lon']
            coordinates['source'] = 'google_maps'
            if 'google_zoom' in osm_info:
                coordinates['zoom'] = osm_info['google_zoom']
        
        # T√¨m ki·∫øm t·ªça ƒë·ªô t·ª´ URL parameters
        if not coordinates.get('latitude'):
            # Ki·ªÉm tra URL hi·ªán t·∫°i c·ªßa driver
            current_url = driver.current_url
            if 'lat=' in current_url and 'lon=' in current_url:
                import re
                lat_match = re.search(r'lat=([0-9.-]+)', current_url)
                lon_match = re.search(r'lon=([0-9.-]+)', current_url)
                zoom_match = re.search(r'zoom=([0-9]+)', current_url)
                
                if lat_match and lon_match:
                    coordinates['latitude'] = lat_match.group(1)
                    coordinates['longitude'] = lon_match.group(1)
                    coordinates['source'] = 'url_parameters'
                    if zoom_match:
                        coordinates['zoom'] = zoom_match.group(1)
    
    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t t·ªça ƒë·ªô: {e}")
    
    return coordinates

def extract_openstreetmap_coordinates(soup, driver):
    """Tr√≠ch xu·∫•t t·ªça ƒë·ªô t·ª´ OpenStreetMap"""
    coordinates = {}
    
    try:
        print("üîç T√¨m ki·∫øm OpenStreetMap elements...")
        
        # T√¨m ki·∫øm div c√≥ id="mapContainer"
        map_container = soup.find('div', id='mapContainer')
        if map_container:
            print("‚úÖ T√¨m th·∫•y mapContainer")
        
        # T√¨m ki·∫øm Leaflet map wrapper
        leaflet_container = soup.find('div', class_=lambda x: x and 'leaflet-container' in x)
        if leaflet_container:
            print("‚úÖ T√¨m th·∫•y Leaflet container")
            
            # T√¨m ki·∫øm tile images ƒë·ªÉ t√≠nh to√°n t·ªça ƒë·ªô
            tile_images = soup.find_all('img', class_='leaflet-tile')
            if tile_images:
                print(f"‚úÖ T√¨m th·∫•y {len(tile_images)} tile images")
                
                # L·∫•y th√¥ng tin t·ª´ tile ƒë·∫ßu ti√™n
                first_tile = tile_images[0]
                tile_src = first_tile.get('src', '')
                
                # Tr√≠ch xu·∫•t th√¥ng tin t·ª´ tile URL
                import re
                tile_pattern = r'https://[a-z]\.tile\.openstreetmap\.org/(\d+)/(\d+)/(\d+)\.png'
                tile_match = re.search(tile_pattern, tile_src)
                
                if tile_match:
                    zoom_level = int(tile_match.group(1))
                    tile_x = int(tile_match.group(2))
                    tile_y = int(tile_match.group(3))
                    
                    print(f"üìç Tile info: zoom={zoom_level}, x={tile_x}, y={tile_y}")
                    
                    # T√≠nh to√°n t·ªça ƒë·ªô t·ª´ tile coordinates
                    lat, lon = tile_to_lat_lon(tile_x, tile_y, zoom_level)
                    
                    # Ki·ªÉm tra xem t·ªça ƒë·ªô c√≥ h·ª£p l√Ω kh√¥ng (trong ph·∫°m vi Vi·ªát Nam)
                    if 8.0 <= lat <= 23.0 and 102.0 <= lon <= 110.0:
                        coordinates['latitude'] = str(lat)
                        coordinates['longitude'] = str(lon)
                        coordinates['zoom'] = str(zoom_level)
                        coordinates['source'] = 'leaflet_tile_calculation'
                        coordinates['tile_x'] = tile_x
                        coordinates['tile_y'] = tile_y
                        
                        print(f"‚úÖ T√≠nh to√°n t·ªça ƒë·ªô t·ª´ tile: {lat}, {lon}")
                    else:
                        print(f"‚ö†Ô∏è  Tile coordinates kh√¥ng h·ª£p l√Ω cho Vi·ªát Nam: {lat}, {lon}")
                        # Kh√¥ng l∆∞u t·ªça ƒë·ªô n√†y
            
            # T√¨m ki·∫øm marker ƒë·ªÉ l·∫•y t·ªça ƒë·ªô ch√≠nh x√°c
            marker = soup.find('img', class_='leaflet-marker-icon')
            if marker:
                print("‚úÖ T√¨m th·∫•y map marker")
                
                # L·∫•y transform style c·ªßa marker
                style = marker.get('style', '')
                transform_match = re.search(r'translate3d\(([^,]+),\s*([^,]+)', style)
                
                if transform_match:
                    marker_x = float(transform_match.group(1).replace('px', ''))
                    marker_y = float(transform_match.group(2).replace('px', ''))
                    print(f"üìç Marker position: x={marker_x}, y={marker_y}")

                    # D√πng m·ªôt tile l√†m m·ªëc ƒë·ªÉ quy ƒë·ªïi marker -> to·∫° ƒë·ªô
                    ref_tile = None
                    for ti in tile_images:
                        if ti.get('src', '').startswith('https://'):
                            ref_tile = ti
                            break
                    if ref_tile:
                        ref_src = ref_tile.get('src', '')
                        m = re.search(r'https://[a-z]\.tile\.openstreetmap\.org/(\d+)/(\d+)/(\d+)\.png', ref_src)
                        mpos = re.search(r'translate3d\(([-0-9.]+)px,\s*([-0-9.]+)px', ref_tile.get('style', '') or '')
                        if m and mpos:
                            z = int(m.group(1))
                            tx = int(m.group(2))
                            ty = int(m.group(3))
                            tile_px = float(mpos.group(1))
                            tile_py = float(mpos.group(2))

                            # Hi·ªáu gi·ªØa marker v√† g√≥c tr√™n-tr√°i c·ªßa tile ref
                            dx = marker_x - tile_px
                            dy = marker_y - tile_py
                            # Quy ƒë·ªïi sang to·∫° ƒë·ªô tile th·ª±c (ph·∫ßn th·∫≠p ph√¢n)
                            adj_tx = tx + (dx / 256.0)
                            adj_ty = ty + (dy / 256.0)
                            lat2, lon2 = tile_to_lat_lon(adj_tx, adj_ty, z)
                            coordinates['latitude'] = str(lat2)
                            coordinates['longitude'] = str(lon2)
                            coordinates['zoom'] = str(z)
                            coordinates['source'] = 'leaflet_marker_ref_tile'
                            coordinates['marker_x'] = marker_x
                            coordinates['marker_y'] = marker_y
                            print(f"‚úÖ T√≠nh to·∫° ƒë·ªô t·ª´ marker + tile: {lat2}, {lon2}")
            
            # T√¨m ki·∫øm trong t·∫•t c·∫£ scripts
            scripts = soup.find_all('script')
            osm_data = {}
            
            for script in scripts:
                if script.string:
                    script_content = script.string
                    
                    # T√¨m ki·∫øm c√°c pattern ƒë·∫∑c bi·ªát cho OpenStreetMap/Leaflet
                    import re
                    osm_patterns = [
                        # Leaflet map initialization
                        r'L\.map\(["\']([^"\']+)["\']\s*,\s*{\s*center:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                        r'setView\(\[([0-9.-]+),\s*([0-9.-]+)\]\s*,\s*([0-9]+)',
                        r'center:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                        
                        # OpenStreetMap specific patterns
                        r'openstreetmap\.org.*?lat=([0-9.-]+).*?lon=([0-9.-]+)',
                        r'osm\.org.*?lat=([0-9.-]+).*?lon=([0-9.-]+)',
                        
                        # React/Next.js map data
                        r'"latitude":\s*([0-9.-]+)',
                        r'"longitude":\s*([0-9.-]+)',
                        r'"lat":\s*([0-9.-]+)',
                        r'"lon":\s*([0-9.-]+)',
                        r'"center":\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                        
                        # JavaScript variables
                        r'lat["\']?\s*=\s*([0-9.-]+)',
                        r'lon["\']?\s*=\s*([0-9.-]+)',
                        r'latitude["\']?\s*=\s*([0-9.-]+)',
                        r'longitude["\']?\s*=\s*([0-9.-]+)',
                        
                        # Map configuration objects
                        r'config["\']?\s*:\s*{[^}]*"lat["\']?\s*:\s*([0-9.-]+)',
                        r'config["\']?\s*:\s*{[^}]*"lon["\']?\s*:\s*([0-9.-]+)',
                        r'options["\']?\s*:\s*{[^}]*"center["\']?\s*:\s*\[([0-9.-]+),\s*([0-9.-]+)\]',
                        
                        # Camera location data
                        r'camera["\']?\s*:\s*{[^}]*"lat["\']?\s*:\s*([0-9.-]+)',
                        r'camera["\']?\s*:\s*{[^}]*"lon["\']?\s*:\s*([0-9.-]+)',
                        r'location["\']?\s*:\s*{[^}]*"lat["\']?\s*:\s*([0-9.-]+)',
                        r'location["\']?\s*:\s*{[^}]*"lon["\']?\s*:\s*([0-9.-]+)'
                    ]
                    
                    for pattern in osm_patterns:
                        matches = re.findall(pattern, script_content, re.IGNORECASE | re.DOTALL)
                        for match in matches:
                            if 'center' in pattern or 'setView' in pattern:
                                if len(match) == 2:
                                    osm_data['center_lat'] = match[0]
                                    osm_data['center_lon'] = match[1]
                                elif len(match) == 3:
                                    osm_data['center_lat'] = match[0]
                                    osm_data['center_lon'] = match[1]
                                    osm_data['zoom'] = match[2]
                            elif 'lat' in pattern or 'latitude' in pattern:
                                osm_data['lat'] = match
                            elif 'lon' in pattern or 'longitude' in pattern:
                                osm_data['lon'] = match
                            elif 'openstreetmap.org' in pattern or 'osm.org' in pattern:
                                if len(match) == 2:
                                    osm_data['osm_lat'] = match[0]
                                    osm_data['osm_lon'] = match[1]
            
            # T√¨m ki·∫øm trong JSON-LD data
            json_ld_scripts = soup.find_all('script', type='application/ld+json')
            for script in json_ld_scripts:
                if script.string:
                    try:
                        data = json.loads(script.string)
                        if isinstance(data, dict):
                            # T√¨m ki·∫øm t·ªça ƒë·ªô trong JSON-LD
                            if 'geo' in data:
                                geo = data['geo']
                                if isinstance(geo, dict):
                                    if 'latitude' in geo:
                                        osm_data['json_ld_lat'] = geo['latitude']
                                    if 'longitude' in geo:
                                        osm_data['json_ld_lon'] = geo['longitude']
                            elif 'location' in data:
                                location = data['location']
                                if isinstance(location, dict):
                                    if 'latitude' in location:
                                        osm_data['json_ld_lat'] = location['latitude']
                                    if 'longitude' in location:
                                        osm_data['json_ld_lon'] = location['longitude']
                    except:
                        pass
            
            # T√¨m ki·∫øm trong meta tags
            meta_tags = soup.find_all('meta')
            for meta in meta_tags:
                name = meta.get('name', '').lower()
                content = meta.get('content', '')
                
                if 'geo.position' in name or 'geo.position-latitude' in name:
                    osm_data['meta_lat'] = content
                elif 'geo.position-longitude' in name:
                    osm_data['meta_lon'] = content
                elif 'geo.coordinates' in name:
                    # Format: "latitude;longitude"
                    if ';' in content:
                        parts = content.split(';')
                        if len(parts) == 2:
                            osm_data['meta_lat'] = parts[0]
                            osm_data['meta_lon'] = parts[1]
            
            # ∆Øu ti√™n t·ªça ƒë·ªô t·ª´ c√°c ngu·ªìn kh√°c nhau
            if 'center_lat' in osm_data and 'center_lon' in osm_data:
                coordinates['latitude'] = osm_data['center_lat']
                coordinates['longitude'] = osm_data['center_lon']
                coordinates['source'] = 'openstreetmap_center'
                if 'zoom' in osm_data:
                    coordinates['zoom'] = osm_data['zoom']
            elif 'lat' in osm_data and 'lon' in osm_data:
                coordinates['latitude'] = osm_data['lat']
                coordinates['longitude'] = osm_data['lon']
                coordinates['source'] = 'openstreetmap_data'
            elif 'osm_lat' in osm_data and 'osm_lon' in osm_data:
                coordinates['latitude'] = osm_data['osm_lat']
                coordinates['longitude'] = osm_data['osm_lon']
                coordinates['source'] = 'openstreetmap_url'
            elif 'json_ld_lat' in osm_data and 'json_ld_lon' in osm_data:
                coordinates['latitude'] = osm_data['json_ld_lat']
                coordinates['longitude'] = osm_data['json_ld_lon']
                coordinates['source'] = 'json_ld'
            elif 'meta_lat' in osm_data and 'meta_lon' in osm_data:
                coordinates['latitude'] = osm_data['meta_lat']
                coordinates['longitude'] = osm_data['meta_lon']
                coordinates['source'] = 'meta_tags'
            
            if coordinates:
                print(f"‚úÖ T√¨m th·∫•y t·ªça ƒë·ªô: {coordinates['latitude']}, {coordinates['longitude']}")
            else:
                print("‚ùå Kh√¥ng t√¨m th·∫•y t·ªça ƒë·ªô trong OpenStreetMap")
        
        # T√¨m ki·∫øm trong iframe OpenStreetMap
        iframes = soup.find_all('iframe')
        for iframe in iframes:
            src = iframe.get('src', '')
            if 'openstreetmap.org' in src or 'osm.org' in src:
                print(f"‚úÖ T√¨m th·∫•y OpenStreetMap iframe: {src}")
                
                # Tr√≠ch xu·∫•t t·ªça ƒë·ªô t·ª´ URL
                import re
                lat_match = re.search(r'lat=([0-9.-]+)', src)
                lon_match = re.search(r'lon=([0-9.-]+)', src)
                zoom_match = re.search(r'zoom=([0-9]+)', src)
                
                if lat_match and lon_match:
                    coordinates['latitude'] = lat_match.group(1)
                    coordinates['longitude'] = lon_match.group(1)
                    coordinates['source'] = 'openstreetmap_iframe'
                    if zoom_match:
                        coordinates['zoom'] = zoom_match.group(1)
                    break
    
    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t t·ªça ƒë·ªô OpenStreetMap: {e}")
    
    return coordinates

def tile_to_lat_lon(tile_x, tile_y, zoom):
    """Chuy·ªÉn ƒë·ªïi tile coordinates th√†nh latitude/longitude"""
    import math
    
    n = 2.0 ** zoom
    lon_deg = tile_x / n * 360.0 - 180.0
    lat_rad = math.atan(math.sinh(math.pi * (1 - 2 * tile_y / n)))
    lat_deg = math.degrees(lat_rad)
    
    return lat_deg, lon_deg

def pixel_to_lat_lon(pixel_x, pixel_y, tile_x, tile_y, zoom):
    """Chuy·ªÉn ƒë·ªïi pixel position th√†nh latitude/longitude"""
    import math
    
    # K√≠ch th∆∞·ªõc tile (256x256 pixels)
    tile_size = 256
    
    # T√≠nh to√°n pixel offset trong tile
    pixel_offset_x = pixel_x % tile_size
    pixel_offset_y = pixel_y % tile_size
    
    # T√≠nh to√°n t·ªça ƒë·ªô tile v·ªõi offset
    adjusted_tile_x = tile_x + (pixel_offset_x / tile_size)
    adjusted_tile_y = tile_y + (pixel_offset_y / tile_size)
    
    # Chuy·ªÉn ƒë·ªïi th√†nh lat/lon
    return tile_to_lat_lon(adjusted_tile_x, adjusted_tile_y, zoom)

def lat_lon_to_tile(lat, lon, zoom):
    """Chuy·ªÉn ƒë·ªïi latitude/longitude th√†nh tile coordinates"""
    import math
    
    lat_rad = math.radians(lat)
    n = 2.0 ** zoom
    tile_x = int((lon + 180.0) / 360.0 * n)
    tile_y = int((1.0 - math.asinh(math.tan(lat_rad)) / math.pi) / 2.0 * n)
    
    return tile_x, tile_y

def global_pixel_to_lat_lon(px, py, zoom, world_size=None):
    """Chuy·ªÉn global pixel (t·ª´ g√≥c tr√™n tr√°i c·ªßa world) sang lat/lon theo Web Mercator.
    px/py: t·ªça ƒë·ªô pixel to√†n c·ª•c trong world
    zoom: m·ª©c zoom
    world_size: k√≠ch th∆∞·ªõc world theo pixel, m·∫∑c ƒë·ªãnh 256 * 2^zoom
    """
    import math
    if world_size is None:
        world_size = 256 * (2 ** zoom)
    x = px / world_size - 0.5
    y = 0.5 - py / world_size
    lon = 360.0 * x
    lat = 90.0 - 360.0 * math.atan(math.exp(-y * 2.0 * math.pi)) / math.pi
    return lat, lon

def strip_accents(text):
    try:
        text = unicodedata.normalize('NFKD', text)
        text = ''.join([c for c in text if not unicodedata.combining(c)])
        return text
    except Exception:
        return text

def translate_vi_title_to_en(text):
    if not text:
        return text or ''
    base = strip_accents(text)
    # M·ªôt s·ªë thay th·∫ø c∆° b·∫£n cho t·ª´ kho√° th∆∞·ªùng g·∫∑p
    replacements = {
        'truc tuyen': 'live',
        'truc tiep': 'live',
        'webcam': 'Webcam',
        'phat truc tiep': 'live',
        'qua webcam': 'via webcam',
        'viet nam': 'Vietnam',
        'da nang': 'Da Nang',
        'quang trung': 'Quang Trung',
    }
    lowered = base.lower()
    for vi, en in replacements.items():
        lowered = lowered.replace(vi, en)
    # Vi·∫øt hoa ch·ªØ c√°i ƒë·∫ßu cho ƒë·∫πp
    return lowered[:1].upper() + lowered[1:]

def infer_city_english(result, url):
    # ∆Øu ti√™n trong breadcrumbs
    try:
        if result.get('location', {}).get('breadcrumbs'):
            for trail in result['location']['breadcrumbs']:
                for crumb in trail:
                    text = str(crumb.get('text', '')).strip()
                    t = strip_accents(text).lower()
                    if 'da nang' in t or 'ƒë√† n·∫µng' in text.lower():
                        return 'Da Nang'
                    # C√≥ th·ªÉ m·ªü r·ªông mapping th√†nh ph·ªë kh√°c n·∫øu c·∫ßn
    except Exception:
        pass
    # D·ª±a v√†o title/h1
    for key in ['page_info']:
        try:
            title = (result.get(key, {}) or {}).get('title', '')
            if title:
                t = strip_accents(title).lower()
                if 'da nang' in t:
                    return 'Da Nang'
        except Exception:
            pass
    # T·ª´ URL
    try:
        if '/da-nang/' in url:
            return 'Da Nang'
    except Exception:
        pass
    return ''

if __name__ == "__main__":
    crawl_and_save_results()
